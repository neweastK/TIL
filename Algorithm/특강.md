# 알고리즘 특강

[toc]

### 무조건 준비해야되는 알고리즘

1. **재귀호출 기본 (백트래킹)**:
2. **DFS, BFS (그래프 탐색)**  :heavy_check_mark:
3. **Binary Search (Parametric 포함)**  :heavy_check_mark:
4. **Heap (P.Q)**
5. **Dijkstra(P.Q 만든 것)**  :heavy_check_mark:
6. **플로이드 (암기)** :heavy_check_mark:
7. **그리디 :heavy_check_mark:**
8. **Union-Find ** :heavy_check_mark:
9. **MST**  :heavy_check_mark:
10. **Sliding Window** 
11. **Hash**
12. **플러드 필**
13. 그 이후
    1. Trie
    2. DP (공부 시간 대비 정답률 즉, 가성비가 좋지 않기 때문에 후순위) :heavy_check_mark:
    3. Segment Tree
    4. 부분합
    5. 정렬 :heavy_check_mark: (병합정렬 빼고)



#### 코테

- 코테 난이도가 높다 = 서류 뚫기가 쉽다 
- 삼성전자, 하이닉스, 현대자동차, 국민은행, 현대카드, 네이버, 카카오 등의 영업이익은 조 단위
  - but, 스타트업의 경우 1000억대만 돼도 매우 높은 수준이라고 생각하면 됨
- 중수 이상이 될 때, 알고리즘을 잘하는 방법
  - 기출 유형을 분석하며 반복적으로 풀어본다
  - 알고리즘을 하나씩 마스터해간다
  - 고수들의 코드를 리뷰해보며 내것으로 만든다
  - 중수란? 삼성 A형 한문제는 스스로 풀 수 있는 정도
- 그렇다면 초보는?
  - 능숙함을 목표로
    - 쉬운 문제는 보다 능숙하게 풀 수 있어야함
    - 쓸 수 있는 라이브러리의 사용법을 익숙하게 사용할 수 있도록 할 것
    - 파이썬 문법을 구글링하는 일은 없어야함
    - 즉, 쉬운 문제부터 지겹게 풀어라
      - JUNGOL 추천해주심 (Beginner Coder 풀면 될듯? 그것도 어려우면 LCoder_Python 풀것)
      - 완전 기초부터 공부하는 것 X, 능숙도를 올리는 것
  - 목표로 해야하는 수준
    - 너무 반복해서 지겨울 정도로 능숙해질 때 까지
    - 단지, 이해한 것만으로 만족하지 말 것 절대절대 (이건 누구나 금방됨)
    - 중수 이상 되지 않을 때는, 쉬운 문제를 더 우선적으로 많이 풀어야함
    - 추천 공부방법 Daily 과제
      - 매일 쉬운 문제 두 문제씩 (난이도가 쉽던, 어렵던 매일 두 문제씩)
      - 보통 컨디션 : 매일 두 문제
      - 좋은 컨디션 : 많이 풀자
  - 문제 풀다 막히면?
    - 풀이를 보지 말고, 더 쉬운 문제를 풀 것







### DP(다이나믹 프로그래밍, 동적계획법)

> 메모리 공간을 약간 더 사용함으로 연산 속도를 비약적으로 증가시킬 수 있는 방법



#### :heavy_check_mark: point!

- 점화식으로 표현이 가능한가? 우선적으로 살펴볼 것
  - 즉, 하나의 문제를 부분 문제로 나누어서 해결할 수 있는지 확인해본다
- 동일한 작업이 반복되는가?
  - 그렇다면 메모이제이션 활용
  - 작업에 대한 결과를 따로 저장한 후, 똑같은 작업을 실행할 때 저장된 결과를 불러오는 것
- 큰 문제를 해결하기 위해 작은 문제를 호출하는 탑다운 방식과 작은 문제부터 차근차근 답을 도출하는 보텀업 방식이 있음
  - 탑다운 방식보다는 보텀업 방식으로 구현하는 것이 더 효율적
  - 만약 탑다운에서 재귀 함수 깊이 오류가 발생하면 sys 라이브러리 이용
    - sys.setrecursionlimit()



#### :framed_picture:frame code (피보나치 수열 구현)

- 탑다운 방식

```python
d=[0]*100

def pibo(x):
    if x==1 or x==2:
        return 1
    elif d[x] !=0:
        return d[x]
    d[x] = pibo(x-2)+pibo(x-1)
    return d[x]
```

- 보텀업 방식

```python
d=[0]*100

d[1] = 1
d[2] = 1

for i in range(3,n+1):
    d[i] = d[i-2]+d[i-1]
print(d[n])
```



### Greedy (탐욕 알고리즘)

> 당장 현재 상황에서 최적이라고 생각되는 해를 선택하는 알고리즘

#### :heavy_check_mark:point!

- 동적 계획법(DP)보다 훨씬 빠르게 동작
- 순간마다 하는 선택은 그 순간에는 최적이지만, 전체로 봤을 때 최적이 아닐 수도 있음
- 따라서, 그리디 알고리즘으로 최적해를 구하기 위해서는 두가지 조건 충족 필요
  1. 탐욕적 선택 속성 (greedy choice property)
     - 탐욕적인 선택이 항상 그 순간의 최적해를 보장해야한다.
     - 현재의 선택은 이후의 선택으로부터 영향을 받지 않는다.
     - 즉, 이미 선택된 것은 번복하지 않는다 (DP와의 가장 큰 차이점) 
  2. 최적 부분 구조 (optimal substructure)
     - 전체 문제의 최적해가 각 부분 문제들의 최적해로 이루어져있다.
- 위 두 조건이 성립되지 않으면 그리디 알고리즘으로 최적해를 구할 수 없다
  - 따라서, 위 조건을 만족하는지 정당성 증명 과정이 반드시 필요



### DFS(깊이 우선 탐색)

> 루트 노드에서 시작해서 다음 분기로 넘어가기 전에 해당 분기를 완벽하게 탐색하는 방법

#### :heavy_check_mark:point!

- 그래프 즉, 노드 간 연결 관계를 표현하는 방법 2가지

  1. 인접 행렬 : 2차원 배열로 그래프의 연결 관계를 표현하는 방식
     - n행 m열은 n번 노드와 m번 노드가 연결되어 있는지를 표현하는 것
  2. 인접 리스트 : 리스트로 그래프의 연결 관계를 표현하는 방식 
     - 인덱스가 노드의 번호가 됨
     - 노드와 거리를 튜플로 하는 값을 가짐

  - 인접 리스트 방식이 인접 행렬 방식에 비해 메모리 공간의 낭비가 적으나 정보를 얻는 시간이 오래 걸림

- 구현 방법에는 두가지가 있음
  1. 재귀함수 이용
  2. stack 이용
- 탐색 시작 노드를 스택에 삽입하며 시작하고, 최상단 노드에 방문하지 않은 인접 노드가 있다면 그 인접 노드를 스택에 넣고 방문 처리를 한다.
  - 스택이 빈 리스트가 될 때까지 반복


#### :framed_picture:frame code

```python
def dfs(graph, v, visited):
    visited[v] = True
    for i in graph[v]:
        if not visited[i]:
            dfs(graph, i, visited)
            
graph = [ 각 노드의 연결 정보 ]
visited = [False]*N
dfs(graph,시작노드,visited)
```

```python
# 재귀 ver
def recursive_dfs(v, visited=[]):
    visited.append(v)
    for w in graph[v]:
        if w not in visited:
            visited = recursive_dfs(w,visited)
    return visited 
```

```python
# stack ver
def dfs(start_v):
    visited=[]
    stack=[start_v]
    while stack :
        v=stack.pop()
        if v not in visited :
            visited.append(v)
            for w in graph[v]:
                stack.append(w)
    return visited
```



:heavy_exclamation_mark: DFS와 DP를 결합한 경우 (백준 1520번 문제 참고)

- 방문 배열에는 3가지 값 중 하나가 들어간다.
  1. `-`1 : 아직 방문하지 않은 경우
  2. `0` : 방문했으나 목적지에 도착하지 못한 경우
  3. `0이상` : 방문했고, 목적지까지 도착할 수 있는 경우의 수
- 만약, 새로 탐색한 곳의 값이 -1이 아닌 값이라면, 그 위치에서 더 깊이 갈 필요가 없음
  - 이미 가봤기 때문에!
  - 따라서, 지금 위치의 값에서 새로 탐색한 곳의 값을 더해준다면, 지금 위치에서 목적지까지 갈 수 있는 경우의 수를 구하게 되는것!
  - 왜냐하면, 깊이 우선 탐색이기 때문에 이미 가본 위치는 더 이상 탐색할 필요가 없음 (이미 다 탐색을 해봤기 때문에)
- 이 방법으로 시간을 매우 효과적으로 줄일 수 있다.

```python
import sys
input = sys.stdin.readline
sys.setrecursionlimit(10**6)

def dfs(x,y):
    # 목적지일 경우 1 반환
    if x==M-1 and y==N-1 :
        return 1
    
    # 이미 방문한 경우, 그 값을 반환
    # 만약, 목적지로 갈 수 없다면 0일 것
    elif visited[x][y] != -1 :
        return visited[x][y]

    else :
        # 방문 표시
        visited[x][y] = 0
        # 4방향 탐색
        for d in range(4):
            nx = x+dx[d]
            ny = y+dy[d]
            # 만약 새로 이동할 수 있는 곳의 조건을 만족한다면
            if 0<=nx<M and 0<=ny<N and maps[nx][ny] < maps[x][y] :
                # 지금 위치의 값은 다음 위치에서 목적지까지 갈 수 있는 경로의 수를 더한 값
                visited[x][y] += dfs(nx,ny)

        return visited[x][y]

M,N = map(int,input().split())
maps = [list(map(int,input().split())) for _ in range(M)]
visited = [[-1]*N for _ in range(M)]
dx = [0,0,-1,1]
dy = [1,-1,0,0]

print(dfs(0,0))
```





### BFS(너비 우선 탐색)

#### :heavy_check_mark:point!

- queue를 이용한다
  - 선입선출의 자료 구조
- 시간을 줄이기 위해 deque 사용
- 현재 위치에서 조건에 해당하는 모든 위치를 queue에 삽입하고 다시 탐색을 진행한다
  - DFS는 조건에 해당하는 첫번째 위치를 기준으로 다시 탐색 시작
  
  

:heavy_exclamation_mark: 몇번째 순회(탐색)인지 횟수 구하기

- 몇번만에 도착했는지를 알고 싶을 때 어떻게 구할 것인가?

- 구글링해서 찾은 방법

  1. 방문횟수 배열(ex. count)을 새로 만든다.

     - count[nx] = count[x]+1

  2. 위치와 방문횟수를 묶어서 튜플로 만든다.

     - (x, cnt) → queue에 넣어줄 때, (nx, cnt+1) 과 같이 넣어준다.

     

#### :framed_picture:frame code

```python
def BFS():
    # queue 선언 (deque를 사용하기도 함)
    queue = []
    # 방문체크를 위한 배열 생성 (문제에 따라 모양은 달라질 수 있음)
    visited = [ [0]*N for _ in range(M) ] 
    
    # 초기값 설정 (출발 지점 지정 & 방문 체크)
    queue.append([si,sj])
    visited[[si][sj] = 1
    
    while queue :
        # 선입선출인 queue 자료구조를 활용. 따라서, 첫번째 값을 빼줘야함
        ci,cj = queue.pop(0)
        
        for d in range(4):
            ni = ci + dx[d]
            nj = cj + dy[d]
            
            # 조건에 맞는지 체크 (범위를 벗어나는지, 방문했던 적이 있는지, 문제에서 제기한 조건과 맞는지 체크)
            if 0<=ni<N and 0<=nj<M and visited[ni][nj] != 1 and condition :
                queue.append([ni,nj])
                visitied[ni][nj] = 1
```



#### :heavy_plus_sign:deque 사용법

- deque는 queue, stack 모두 구현 가능하다.
- 양쪽 끝 모두에서 자료의 삽입과 삭제가 가능

```python
from collections import deque

q1 = deque()
q2 = deque([1,2,3])

## deque 메서드

q1.append(item)
q1.appendleft(item)
q1.pop(item)
q1.popleft(item)
q2.extend(array)
q2.extendleft(array)
q1.remove(item)
q1.clear() # deque의 모든 요소 삭제
q1.rotate(n) # n만큼 회전 (양수 : 시계방향, 음수 : 반시계방향)
q1.reverse() # 제자리에서 반대로 뒤집으며 반환값 없음
q1.insert(i,x) # i위치에 x 삽입
q1.index(x[,start[,stop]]) # x의 위치를 반환
q1.count(x) # x와 같은 값의 개수
```

[공식문서](https://docs.python.org/3/library/collections.html#collections.deque)



### Dijkstra (다익스트라)

> 특정 노드에서 다른 모든 노드까지의 최단 거리를 계산하는 알고리즘

#### :heavy_check_mark: point!

- 가장 대표적인 최단 경로 알고리즘
- **특정한 노드에서 출발하여 다른 모든 노드로 가는 최단 경로를 계산**
- **음의 간선이 없을 때 정상적으로 동작**
- 매 상황에서 가장 비용이 적은 노드를 선택해 임의의 과정을 반복
- 한 단계당 하나의 노드에 대한 최단 거리를 확실히 찾을 수 있음
- 시간 복잡도를 낮추기 위해 우선순위 큐 활용



#### :arrow_forward: 동작 과정

1. 출발 노드 설정
2. 최단 거리 테이블을 초기화
   1. 자기 자신에 대한 노드는 0으로 설정
   2. 초기에는 자기 자신에 대한 노드를 제외한 나머지 노드로 가는 비용을 모두 무한으로 설정
3. 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드 선택 (heapq를 활용)
4. 해당 노드를 거쳐 다른 노드로 가는 비용을 계산하여 최단 거리 테이블을 갱신
5. 위 과정에서 3번, 4번 반복



#### :heavy_plus_sign:우선순위 큐 사용법

- 우선순위가 가장 높은 데이터를 가장 먼저 삭제하는 자료구조
- 힙(Heap) : 우선순위 큐를 구현하기 위해 사용하는 자료구조 
  - 최소힙(Min Heap)과 최대힙(Max Heap)으로 구분 (기본적으로 최소힙으로 동작)
    - 최대힙을 만들고 싶으면 append시 값을 음수로 만들어서 삽입
  - 삽입시간과 삭제시간 모두 O(logN) 만큼의 수행시간 소요

```python
import heapq

heapq.heappush(대상, 삽입할 값)
heapq.heappop(대상) # 가장 작은 원소를 삭제 후 반환
# 삭제 없이 반환을 원한다면 인덱스 사용 
heapq.heapify(대상) # 기존 리스트를 힙으로 변환
# 최대힙 뽑기
nums = [4, 1, 7, 3, 8, 5]
heap = []

for num in nums:
  heapq.heappush(heap, (-num, num))  # (우선 순위, 값)

while heap:
  print(heapq.heappop(heap)[1])  # index 1
```

- 우선순위 큐를 다익스트라에 사용할 때, 거리가 가까워서 값이 갱신된 경우에만 우선순위 큐에 넣어준다.

#### :framed_picture:frame code

```python
import heapq

# n, m == 노드 개수, 간선 개수

# 0번 노드가 없다면 n+1로 설정 (편리성을 위해)
# graph에는 (비용, 목적지)의 튜플이 들어감
# graph[x]에는 x에서 출발하여 v까지 가는데 c만큼 비용이 든다는 정보가 들어있음
graph = [[] for _ in range(n+1)]

# start 노드에서 각 index번 노드까지의 최소 거리
distance = [int(1e9)]*(n+1)

def djikstra(start):
    queue = []
    heapq.heappush(queue,(0,start))
    # start 노드에서 start노드. 즉, 본인까지의 거리는 0
    distance[start] = 0
    
    while queue :
        dist,target = heapq.heappop(queue)
        
        if distance[target] < dist :
            continue
        
        # start노드에서 출발해 target노드를 거쳐 가는 것이 더 짧은지 비교 
        for i in graph[target] :
            cost = dist + i[0]
            if cost < distance[i[1]] :
                distance[i[1]] = cost
                heapq.heappush(queue,(cost,i[0])) 
```

- 왜 굳이 heapq를 써서, 거리가 짧은 것부터 돌리는걸까?
  - 시간복잡도를 줄이기 위함
  - heapq를 쓰지 않으면 노드가 5000개 이상일 경우 시간 초과가 남
  - **지금까지 풀 때, (거리, 노드) 형태가 아니고 (노드,거리) 형태로 썼는데 그러면 heapq를 쓰는 의미가 없겠다.**



### Floyd-Warshall(플로이드 워셜)

> 모든 노드 간의 최단거리를 구하는 알고리즘

#### :heavy_check_mark: point!

- 다익스트라와 다르게 음의 간선이 있어도 활용 가능
- 모든 노드에서 다른 모든 노드까지의 최단거리를 구함
- 시간복잡도가 매우 크므로, 데이터의 개수가 적을 때 사용 가능



#### :arrow_forward: 동작 과정

1. 각 노드 간 거리를 2차원 배열에 저장한다
   1. 자기 자신까지의 거리는 0, 연결되지 않은 노드는 INF로 설정
2. 각 노드를 순회하는데, 이때, 노드는 거쳐가는 노드를 뜻함
   1. 예를 들어, 1번 노드를 경유해서 가는 경우를 확인해보는 것
   2. 2번 노드 - 3번 노드 vs 2번 노드 - 1번 노드 - 3번 노드 를 비교해서 더 짧은 값으로 바꿔주기
   3. 이 과정을 계속 반복
3. 최종적으로 2차원 배열에서 각 노드간 최단거리를 알 수 있음



#### :framed_picture:frame code

```python
import sys

input = sys.stdin.readline
INF = int(1e9)

# 노드의 개수(n)과 간선의 개수(m) 입력
n = int(input())
m = int(input())

# 2차원 리스트 (그래프 표현) 만들고, 무한대로 초기화
graph = [[INF] * (n + 1) for _ in range(n + 1)]

# 자기 자신에서 자기 자신으로 가는 비용은 0으로 초기화
for a in range(1, n + 1):
    for b in range(1, n + 1):
        if a == b:
            graph[a][b] = 0

# 각 간선에 대한 정보를 입력받아, 그 값으로 초기화
for _ in range(m):
    # A -> B로 가는 비용을 C라고 설정
    a, b, c = map(int, input().split())
    graph[a][b] = c

# 점화식에 따라 플로이드 워셜 알고리즘을 수행
for k in range(1, n + 1):
    for a in range(1, n + 1):
        for b in range(1, n + 1):
            graph[a][b] = min(graph[a][b], graph[a][k] + graph[k][b])

# 수행된 결과를 출력
for a in range(1, n + 1):
    for b in range(1, n + 1):
        if graph[a][b] == INF:
            print('INFINITY', end=' ')
        else:
            print(graph[a][b], end=' ')
    print()
```





### Union-Find(합집합 찾기)

> 서로소 집합(Disjoint-Set) 알고리즘이라고도 부른다.
>
> 여러 개의 노드가 존재할 때 두 개의 노드를 선택해서 현재 이 두 노드가 서로 같은 그래프에 속하는지 판별하는 알고리즘

#### :heavy_check_mark: point!

- 노드를 합치고(union), 속한 집합을 찾아(find) 서로소 집합을 찾아낸다(disjoint set)

- 초기 배열
  - 인덱스는 몇번 노드인지 나타내고, 값은 부모 노드의 번호를 나타냄
  - 초기값으로는 모두 자기 자신을 부모 노드로 갖도록 한다
- 연결관계가 생겼을 때, 주로 더 작은 값을 부모 노드로 설정해준다.
  - ex) 1번 노드와 2번 노드가 연결되면 부모 노드는 1번
- union find의 핵심은 조상 노드를 찾는 것
  - 그렇게 두개의 노드가 같은 집합에 속하는지 확인하는 것



#### :framed_picture:frame code

```python
# 각 노드의 부모를 가리키는 배열, 초기값은 자기 자신
parent = [0,1,2,3,4]

# 1. 원소가 속한 집합을 찾는 함수 (재귀함수)
def find(x):
    if parent[x] != x:
        return find(parent[x])
    else :
        return x
    
# 1-1. 경로 압축으로 시간 복잡도 줄이기
def find_parent(x):
    # 루트 노드가 아니라면, 루트 노드를 찾을 때까지 재귀적으로 호출
    # 그리고 본래 부모노드를 나타내도록 했지만, 바로 루트노드를 가르키도록 함
    if parent[x] != x :
        parent[x] = find(parent[x])
        return parent[x]
    else :
        return x

# 2. 두 부모 노드를 합치는 함수 (두 노드를 연결한다)
# 더 작은 번호의 노드를 부모로 삼는다
def union(a,b):
    a = find(a)
    b = find(b)
    if a < b:
        parent[b] = a
    else :
        parent[a] = b
# 여기서 넣어준 값에 find 결과 즉, 최상위 부모로 덮어써도 되는 이유
# - 최종 비교할 때도 find로 비교하면 되기 때문
# - 즉, parent 배열에서 나의 조상 노드를 적어주지 않는 경우도 있음.
# - find 함수로 조상 노드를 찾아가게함

# 3. 같은 집합인지 비교 (A,B가 같은 집합인가?)
if find(A) == find(B):
    print("같음")
else :
    print("다름")
```



### MST(최소 신장 트리): Minimum Spanning Tree

> 신장 트리 : 하나의 그래프가 있을 때 **모든 노드를 포함**하면서 **사이클이 존재하지 않는** 부분 그래프 
>
> 최소신장트리 : 최소한의 비용으로 만들 수 있는 신장 트리

#### :heavy_check_mark: point!

- Union-Find를 이용한다
- 간선 데이터들을 가중치를 기준으로 오름차순 정렬한다.
- 간선을 순회하면서 현재의 간선이 사이클을 발생시키는지(== 이미 연결 되어있는지 == 이미 같은 집단인지) 확인한다.
  - 사이클이 발생하지 않으면: 최소 신장 트리에 포함시킨다 == 가중치를 더한다.
  - 사이클이 발생하면: 아무런 작업 없이 다음으로 넘어간다.
    - == 이미 연결시켰다면 어차피 이전에 연결시킨 값이 가장 낮은 가중치를 갖고 있으므로 아무런 작업 없이 넘어간다
- 모든 간선을 확인하고 가중치값을 확인한다.
- 중간에 싸이클이 만들어져도 아직 연결되지 않은 남은 노드들이 있을 수 있음.
  따라서, 모든 노드들을 확인했었는지 반드시 체크할 것

#### :framed_picture:frame code

```python
# 각 노드의 부모를 가리키는 배열, 초기값은 자기 자신
parent = [0,1,2,3,4]

# 1 Union-Find 함수 정의
def find_parent(x):
    if parent[x] != x :
        parent[x] = find(parent[x])
        return parent[x]
    else :
        return x

def union(a,b):
    a = find(a)
    b = find(b)
    if a < b:
        parent[b] = a
    else :
        parent[a] = b

# 노드와 간선의 정보
V,E = map(int,input().split())
parent = [0]*(V+1)

for i in range(1,V+1):
    parent[i] = i

# 모든 간선을 담을 리스트와 최종 가중치를 저장할 변수
edges = [] 
res = 0

# 모든 간선에 대한 정보 담기
# 주어지는 정보가 (a,b,c) = a와 b를 연결하는 간선의 가중치 c 일때
for _ in range(E):
    a,b,c = map(int,input().split())
    edges.append((cost,a,b))
    
# 정렬
edges.sort()
# 만약 cost가 맨 뒤면 key 이용: edges.sort(key=lambda x:x[2])

# 간선 확인
for edge in edges:
    cost, a, b = edge
    # 사이클이 없다면 (== 연결되어있지 않다면 == 같은 집단이 아니라면)
    if find_parent(a) != find_parent(b):
        # 같은 집단으로 정의 (연결)
        union(parent,a,b)
        # 가중치 더해주기
        res += cost
```



### Binaray Search(이분 탐색)

> 정렬된 배열에서 탐색 범위를 절반씩 줄여가며 값의 위치를 찾아내는 알고리즘
>
> 시간복잡도는 O(logN)으로 선형탐색보다 훨씬 빠르다



#### :heavy_check_mark: point!

- 반드시 배열은 정렬되어 있는 상태여야 한다.
- 탐색 범위가 2천만이 넘어가고 처리해아할 데이터의 개수가 천만 단위 이상으로 넘어가면 이진탐색을 떠올릴 것!



#### :arrow_forward: 동작 과정

1. 탐색할 배열의 시작점과 끝점을 설정(초기값은 0과 len(배열)이 될 것)
2. 배열의 가운데 요소의 인덱스를 pivot으로 설정
3. 해당 요소가 찾고자 하는 값이면 검색 완료
4. 아닐 경우
   1. 배열[pivot]이 찾고자 하는 값보다 크다면 탐색할 배열의 끝점을 pivot으로 설정
   2. 배열[pivot]이 찾고자 하는 값보다 작다면 탐색할 배열의 시작점을 pivot으로 설정
5. 배열 내부에 값이 없을 수도 있음
   1. 중단 조건 필요
   2. 시작점과 끝점을 재설정했을 때, 시작점이 더 크게되면 모든 영역을 탐색했다는 뜻이므로 중단



#### :framed_picture:frame code

##### 반복문

```python
# arr==배열, value==원하는 값
first, last = 0, len(arr)

while first <= last:
    mid = (first + last) // 2
    if arr[mid] == value:
        return mid
    if arr[mid] > value:
        last = mid - 1
    else:
        first = mid + 1
```

##### 재귀

```python
def binarySearch(array,target,left,right):
    if left>right:
        return False
    
    pivot = (left+right)//2
    if target == array[pivot]:
        return pivot
    elif target > array[pivot]:
        binarySearch(array,target,pivot,right)
    else:
        binarySearch(array,target,left,pivot)
    
```



#### :heavy_plus_sign:Parametric Search(매개변수 탐색)

> 최적화 문제를 결정 문제로 바꾸어 푸는 것.
>
> ​	즉, 최대, 최소를 찾는 문제를 O,X로 바꿔서 접근하는 방식
>
> 최적화 문제 : 특정의 집합 위에서 정의된 실수값, 함수, 정수에 대해 그 값이 최대나 최소가 되는 상태를 해석하는 문제
>
> 결정 문제 : 특정 값이 어떠한 조건을 만족하는지 확인하는 문제. (Yes or No로 대답할 수 있는 문제)
>
> 이분탐색과 마찬가지로 O(logN)의 시간복잡도를 가짐



#### :heavy_check_mark: point!

- 특정 조건을 만족하는 최댓값/최솟값을 구하는 형식의 문제여야함
- 최댓값을 구하는 문제의 경우 어떤 값이 조건을 만족하면, 그 값보다 작은 값은 모두 조건을 만족해야한다.
- 최솟값을 구하는 문제의 경우 어떤 값이 조건을 만족하면, 그 값보다 큰 값은 모두 조건을 만족해야한다.
- 최적화 문제를 결정 문제로 바꾸어 푸는 경우의 예시
  - 최적화 : 자동차를 탈 수 있는 사람 중 나이가 가장 어린 사람은?
  - 결정 : 자동차를 탈 수 있는가?
- **이분 탐색은 특정 값을 찾으면 탐색을 끝내지만, 파라메트릭 서치는 더 이상 탐색할 배열이 없을 때까지 탐색해야함**







### LIS

> Longest Increasing Subsequence: 가장 긴 부분 증가 수열
>
> - 한 수열의 부분 수열 내에서, 원소들이 오름차순인 부분 수열 중 길이가 가장 긴 수열이 최장 증가 부분 수열
> - 원소가 n개인 배열의 일부 원소를 골라내서 만든 부분 수열 중, **각 원소가 이전 원소보다 크다는 조건을 만족하고, 그 길이가 최대인 부분 수열**
> - ex) [10,20,10,30,20,50] 의 리스트가 있을 때 LIS는 [10,20,30,50]



#### :heavy_check_mark: point!

- DP를 통해 구현하는 방법과 이분탐색을 활용해 구현하는 방법이 있음
  - DP 구현의 시간복잡도는 O(n^2), 이분탐색 구현의 시간복잡도는 O(nlogn)이 된다
  - 따라서, 입력값의 개수에 따라서 DP로 해결이 될 수도 있고 안될 수도 있음

  

###### DP로 구현

- DP 배열이 의미하는 것은 dp[i] 는 array[:i+1]까지의 LIS를 의미
- 반복문을 통해 현재 위치와 이전 dp[:i], array[:i]를 각각 비교
- array[1]이 현재 위치 값보다 작으면 LIS가 증가할 수 있으므로, 현재 LIS와 dp[1]+1 값 중 큰 값으로 대체
  - 이 과정을 array[1]부터 array[i]까지 반복
  - 그러면 결국 LIS는 가장 큰 값만 남게 되고 해당 값이 dp[현재위치]가 됨




##### :framed_picture:frame code

```python
array = [10,20,10,30,20,50]
dp = [1]*N

for i in range(1,N):
    for j in range(0,i):
        if array[i]>array[j]:
            dp[i] = max(dp[j]+1,dp[i])
    
```



###### 이분탐색으로 구현

- 기본적으로 LIS 배열을 구하는 것이 아닌 **LIS의 길이를 구하는 것!!**
- 원본 배열을 순회하면서 각 값이 결과 배열 어디로 들어갈 수 있는지 확인한다
- 결과 배열의 가장 큰 값 (== 가장 마지막에 위치한 값)과 원본 배열의 값을 비교
  - 만약, 원본 배열의 값이 더 크다면 결과 배열 맨뒤에 추가
  - 원본 배열의 값이 더 작다면 결과 배열 어디로 들어갈 수 있는지 이분탐색을 활용하여 확인
    - **bisect 라이브러리로 쉽게 구현할 수 있음**
- 원본 배열 마지막까지 순회했을 때의, 결과배열의 길이가 LIS 길이
- 정확한 LIS 배열을 구하고 싶다면 새로운 배열 필요
  - 원본 배열을 순회할 때, 해당 값이 결과 배열의 몇번째 인덱스에 들어가는지 기록
  - 순회가 끝나고 새로운 배열의 값이 가장 큰 것부터 탐색
    - 예를 들어, LIS의 길이가 5라면 원본배열[새로운 배열의 값이 5인 인덱스], 원본배열[새로운 배열의 값이 4인 인덱스], 원본배열[새로운 배열의 값이 3인 인덱스] ... 와 같이 찾으면 LIS 배열을 구할 수 있음



##### :framed_picture:frame code

```python
# 만약 이분탐색을 직접 구현하고 싶지 않다면
from bisect import bisect_left

array = [10,20,10,30,20,50]
res = [0]
# LIS 배열을 구하기 위한 배열
record = [0]*len(array)

def binary_search(start,end,target):
    if start>end:
        return start
    mid = (start+end)//2
    
    if res[mid] > target:
        return binary_search(start,mid-1,target)
    elif res[mid] == target:
        return mid
    else:
        return binary_search(mid+1,end,target)
    
for i in range(len(array)):
    if res[-1]<array[i]:
        res.append(array[i])
        record[i] = len(res)
    else:
        # 만약 라이브러리를 쓴다면
        # bisect_left(arr,x) ==> arr배열에 x가 들어갈 위치를 구하는 라이브러리
        idx = bisect_left(res,array[i])
        # 라이브러리를 안쓰면
        idx = binary_search(0,len(res),array[i])
        res[idx] = array[i]
        record[i] = idx

        
# LIS의 길이
print(len(res))

# 원본 LIS 배열 구하기
res_idx = len(res)
ans = []
for j in range(len(array)-1,-1,-1):
    if record[j] == res_idx:
        ans.append(array[j])
        res_idx -= 1
print(ans[::-1])
```





 ### 정렬

#### 선택 정렬(Selection Sort)

> 데이터 중 가장 작은 데이터를 선택해 맨 앞에 있는 데이터와 바꾸고, 그 다음 작은 데이터를 선택해 앞에서 두번째 데이터와 바꾸는 과정을 반복
>
> 즉, 매번 가장 작은 데이터를 선택하여 위치를 정하는 정렬 알고리즘



##### :heavy_check_mark: point!

- 선택정렬의 시간복잡도는 O(N^2)
- 데이터의 개수가 10,000개 이상이면 속도가 급격히 느려짐
- **심지어는 기본 정렬 라이브러리보다도 느림**



##### :framed_picture:frame code

```python
array = [7,5,9,0,3,1,6,2,4,8]

for i in range(len(array)):
    min_idx = i
    for j in range(i+1,len(array)):
        if array[min_idx]>array[j]:
            min_idx = j
    array[i],array[min_idx] = array[min_idx],array[i]
print(array)
```





#### 삽입 정렬(Insertion Sort)

> 특정한 데이터를 적절한 위치에 삽입하는 정렬법
>
> - 해당 데이터 앞의 값들과 비교하면서 적절한 위치 찾기
>
> 적절한 위치에 들어가기 이전에 그 앞까지의 데이터는 이미 정렬되어 있다고 가정
>
> - 앞의 데이터와 비교하다가 더 작은 데이터를 만나면 탐색 중지(정렬되어있기 때문에 더 앞으로 가도 모두가 나보다 작은 데이터일뿐)



##### :heavy_check_mark: point!

- 선택정렬의 시간복잡도는 O(N^2)
- 현재 데이터가 거의 정렬되어 있는 상태라면 매우 빠르게 동작
  - 최선의 경우 O(N)의 시간복잡도
- 두번째 값부터 탐색 시작



##### :framed_picture:frame code

```python
array = [7,5,9,0,3,1,6,2,4,8]

for i in range(1,len(array)):
    for j in range(i,0,-1):
	    if array[j]<array[j-1]:
            array[j],array[j-1] = array[j-1],array[j]
        else:
            break
print(array)
```



#### 퀵 정렬(Quick Sort)

> 분할 정복 방법을 통해 리스트 정렬
>
> - 분할 정복 방법 : 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략
>
> 기준을 설정한 다음 기준보다 작은 수는 왼쪽에, 큰 수는 오른쪽으로 이동시켜 리스트를 반으로 나누는 방식



##### :heavy_check_mark: point!

- 퀵정렬의 시간복잡도는 최악의 경우 O(N^2), 평균적으로 O(nlogn)
  - 삽입정렬과는 반대로 현재 데이터가 거의 정렬되어 있는 상태라면 매우 느리게 동작

- 재귀함수를 이용한다.
- 적어도 한번의 과정에서 피벗의 위치는 고정할 수 있기 때문에 언젠가는 정렬이 완료된다



##### :arrow_forward: 동작 과정

1. 배열의 가장 왼쪽에 있는 하나의 원소를 고른다. (==피벗)
2. 배열의 왼쪽부터 피벗보다 큰 값을 찾을 때까지 탐색한다.
3. 배열의 오른쪽부터 피벗보다 작은 값을 찾을 때까지 탐색한다.
4. 모두 찾았으면 서로 위치를 바꿔준다.
5. 만약, 피벗보다 작은값의 위치가 큰값의 위치보다 앞에 있다면. 즉, 탐색하다가 서로 엇갈렸을 경우에는 피벗과 작은 값의 위치를 바꿔준다
   1. 엇갈렸다는 것은 이제 피벗 값을 기준으로 분리가 완료됐다는 것
6. 피벗과 작은값의 위치를 바꿔주었으면, 피벗을 기준으로 분리된 두 리스트에서도 1부터 동일한 작업을 진행한다.
   1. pivot 값보다 작은 값들은 모두 왼편으로 몰고, 큰 값들은 모두 오른편으로 몰면 기준값은 정확히 정렬된 위치에 놓이게 됨.
      또한 이런 방식으로 분할을 해놓으면 앞으로 더 이상 왼편에 있는 값들과 오른편에 있는 값들 간에는 비교를 할 필요가 없음
7. 리스트의 길이가 1이면 정렬이 끝났다는 뜻이므로 종료



##### :framed_picture: frame code

```python
array = [5, 7, 9, 0, 3, 1, 6, 2, 4, 8]

def quick_sort(array, start, end):
    if start >= end: # 원소가 1개인 경우 종료
        return
    pivot = start # 피벗은 첫 번째 원소
    left = start + 1
    right = end
    while left <= right:
        # 피벗보다 큰 데이터를 찾을 때까지 반복 
        while left <= end and array[left] <= array[pivot]:
            left += 1
        # 피벗보다 작은 데이터를 찾을 때까지 반복
        while right > start and array[right] >= array[pivot]:
            right -= 1
        if left > right: # 엇갈렸다면 작은 데이터와 피벗을 교체
            array[right], array[pivot] = array[pivot], array[right]
        else: # 엇갈리지 않았다면 작은 데이터와 큰 데이터를 교체
            array[left], array[right] = array[right], array[left]
    # 분할 이후 왼쪽 부분과 오른쪽 부분에서 각각 정렬 수행
    quick_sort(array, start, right - 1)
    quick_sort(array, right + 1, end)

quick_sort(array, 0, len(array) - 1)
print(array)
```

- 분할과 정렬 함수를 분리 & pivot을 시작점이 아닌 중간에 위치한 값으로 적용

```python
def quick_sort(arr):
    def sort(start, end):
        if end <= start:
            return

        mid = partition(start, end)
        sort(start, mid - 1)
        sort(mid, end)

    def partition(start, end):
        pivot = arr[(start + end) // 2]
        while start <= end:
            while arr[start] < pivot:
                start += 1
            while arr[end] > pivot:
                end -= 1
            if start <= end:
                arr[start], arr[end] = arr[end], arr[start]
                start, end = start + 1, end - 1
        return start

    return sort(0, len(arr) - 1)
```

- pivot의 위치는 신경쓰지 말고, 즉, 첫 코드는 pivot의 위치가 고정되지만 이 코드는 X
- start 는 무조건 pivot보다 큰 값을 찾고, end는 무조건 pivot보다 작은 값을 찾는다
- start와 end가 교차됐다는 것은, start 이후로는 pivot 보다 작은 값이 없다는 뜻 (pivot>=), start 이전으로는 pivot보다 큰 값이 없다는 뜻 (pivot<)
  - 따라서, 새로운 파티션 범위를 (start,start-1)과 (start,end)로 잡는 것



##### :heavy_plus_sign:최악의 경우 피하기

- 피벗을 랜덤으로 선택
- **배열의 가장 첫 인덱스, 끝 인덱스, 중간 인덱스에 해당하는 값들을 정렬하여 중간값을 피벗으로 사용**
- 배열의 길이가 특정 수(약 200) 이하라면 삽입 정렬을 사용하고 크다면 퀵 정렬을 사용



#### 계수 정렬(Count Sort)

> - 주어진 배열의 값 범위가 작은 경우 빠른 속도를 갖는 정렬 알고리즘
> - 단, 사용하기에 엄격한 제한 조건이 있음
> - 가장 큰 데이터+1을 길이로 하는 빈 배열 생성후 각 위치에 해당 인덱스를 값으로 갖는 원소의 개수를 세는 방법
> - 간단히 말하면, 각 값의 개수를 세는 배열을 만들어서 해당값을 출력하는 방법



##### :heavy_check_mark: point!

- 계수 정렬의 시간 복잡도는 O(N)

- 단, 데이터 값이 정수여야만 함 (x>=0)

- 값의  범위에도 제한이 있음
  - 일반적으로 가장 큰 뎅터와 가장 작은 데이터의 차이가 1,000,000을 넘지 않을 때 효과적

- 따라서, 데이터의 크기가 한정되어 있고, 데이터의 크기가 많이 중복되어 있을 수록 유리

- 누적합 배열을 통해 특정 값의 위치만 추적할 수도 있음
  - [참고블로그](https://jeonyeohun.tistory.com/103)




##### :framed_picture: frame code

```python
array = [7,5,9,0,3,1,6,2,9,1,4,8,0,5,2]

count = [0]*(max(array)+1)

# 데이터 개수
for i in range(len(array)):
    count[array[i]]+=1

# 데이터 바로 출력
for j in range(len(count)):
    for k in range(count[j]):
	    print(j, end=' ')

# 누적합
agg = count[:]
for a in range(1,len(agg)):
    agg[a] += agg[a-1]

# 결과값 할당
res = [0]*(len(array)+1)
for r in array[::-1]:
    res[agg[r]] = r
    agg[r] -= 1

print(res)
```





#### 위상 정렬(Topology Sort)

> 각 정점들이 가지는 위상에 따라서, 그래프를 구성하는 정점들을 순서대로 정렬하는 것
>
> 노드들 간의 선후 관계를 고려하여 정렬을 수행하는 것
>
> 순서가 정해져있는 작업을 차례로 수행해야할 때, 순서를 결정하는 알고리즘

##### :heavy_check_mark: point!

- 그래프 조건 
  - 그래프 간선은 방향성을 가져야함
  - 그래프 내부에 순환(=Cycle)이 있으면 안됨
- 진입차수 활용
  - 진입차수란?
    - 현재 노드를 가리키고 있는 노드의 개수
    - 자기 자신으로 연결되어 들어오는 간선의 개수
    - 한 정점으로 들어오는 간선의 개수
- Queue와 Stack 모두를 사용할 수 있음
  - Queue 사용시, 동일한 레벨에 있는 노드들 우선 확인
    - 따라서, 동일한 레벨의 노드를 확인할 수 있음
  - Stack 사용시, 최대로 들어갈 수 있는 노드까지 탐색
- 따라서, 필요한 정보는 총 3가지
  - 그래프
  - Stack or Queue
  - 진입차수(in-degree)



##### :arrow_forward: 동작 과정

1. 각 노드들을 순회하면서 진입 차수 확인 및 배열 생성
   1. 진입 차수가 0인 정점을 큐에 삽입
2. 큐에서 원소를 꺼내 해당 원소에 연결된 간선 제거
   1. 꺼낸 원소는 위상 정렬의 결과이므로 따로 저장
3. 간선 제거 후 진입 차수가 0이 된 정점을 큐에 삽입
4. 위 과정 반복
   1. 만약 모든 정점을 방문하기 전에 큐가 비게 된다면 싸이클이 존재한다는 뜻



##### :framed_picture:frame code

```python
from collections import deque

N,M = map(int,input().split()) # 그래프 정점의 수, 간선 개수
graph = [[] for _ in range(N+1)]
queue = deque([])
answer = []
# 진입차수
indegree = [0]*(N+1)

# 연결정보 등록 및 진입차수 갱신
for _ in range(M):
    a,b = map(int,input().split())
    graph[a].append(b)
    indegree[b] += 1

for i in range(1,N+1):
    if indegree[i] == 0:
        queue.append(i)

while queue:
    now = queue.popleft()
    answer.append(now)
    for j in graph[now]:
        indegree[j] -= 1
        if indegree[j] == 0:
            queue.append(j)
print(answer)
```

